{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook look at whether ensemble of traditional NLP and neural NLP will produce good result. This could be very much an overkill, but it would be interesting to explore nontheless. </n>\n",
    "\n",
    "In summary, traditional NLP with hand crafted features and random forest produced a f1 score of 0.88, whereas the fine-tuned pre-trained BERT model produced an accuracy score of around 94%. The intuition of combining these two models is that hand crafted features very much captures frequencies of certain words or types of words. Pre-train BERT model has a better understanding of the language as a whole, and this could help identify different writing styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "from prep_bert import *\n",
    "from ensemble import *\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenised-data.pickle', 'rb') as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>class_label</th>\n",
       "      <th>class_id</th>\n",
       "      <th>text</th>\n",
       "      <th>ents_rep</th>\n",
       "      <th>vocab</th>\n",
       "      <th>ppo_rep</th>\n",
       "      <th>no_ents_text</th>\n",
       "      <th>verb_present</th>\n",
       "      <th>verb_past</th>\n",
       "      <th>...</th>\n",
       "      <th>ad</th>\n",
       "      <th>prob</th>\n",
       "      <th>lem_text</th>\n",
       "      <th>len</th>\n",
       "      <th>org_count</th>\n",
       "      <th>place_count</th>\n",
       "      <th>time_count</th>\n",
       "      <th>person_count</th>\n",
       "      <th>num_count</th>\n",
       "      <th>ne_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.nytimes.com/2020/08/17/world/afric...</td>\n",
       "      <td>Incident Report</td>\n",
       "      <td>0</td>\n",
       "      <td>advertisement supported by the extremist group...</td>\n",
       "      <td>1.52</td>\n",
       "      <td>0.570312</td>\n",
       "      <td>1.71875</td>\n",
       "      <td>advertisement support extremist group ORG esca...</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.0703125</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119792</td>\n",
       "      <td>0</td>\n",
       "      <td>[advertisement, support, extremist, group, ORG...</td>\n",
       "      <td>384</td>\n",
       "      <td>0.059896</td>\n",
       "      <td>0.057292</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.026042</td>\n",
       "      <td>0.015625</td>\n",
       "      <td>0.143229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.bbc.com/news/world-europe-54500555</td>\n",
       "      <td>Incident Report</td>\n",
       "      <td>0</td>\n",
       "      <td>belarusian riot police have used water cannon ...</td>\n",
       "      <td>1.41333</td>\n",
       "      <td>0.57716</td>\n",
       "      <td>1.54902</td>\n",
       "      <td>NORP riot police water cannon stun grenade bre...</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>0.0432099</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.00154321</td>\n",
       "      <td>[NORP, riot, police, water, cannon, stun, gren...</td>\n",
       "      <td>648</td>\n",
       "      <td>0.030864</td>\n",
       "      <td>0.026235</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.064815</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.121914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.aljazeera.com/news/2020/10/12/nago...</td>\n",
       "      <td>Incident Report</td>\n",
       "      <td>0</td>\n",
       "      <td>russian foreign minister calls on armenia and ...</td>\n",
       "      <td>2.2518</td>\n",
       "      <td>0.372881</td>\n",
       "      <td>2.62887</td>\n",
       "      <td>NORP foreign minister call GPE GPE adhere agre...</td>\n",
       "      <td>0.0209847</td>\n",
       "      <td>0.0524617</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0992736</td>\n",
       "      <td>0.00161421</td>\n",
       "      <td>[NORP, foreign, minister, call, GPE, GPE, adhe...</td>\n",
       "      <td>1239</td>\n",
       "      <td>0.066182</td>\n",
       "      <td>0.092010</td>\n",
       "      <td>0.033091</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>0.205811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://counteriedreport.com/roadside-bomb-bla...</td>\n",
       "      <td>Incident Report</td>\n",
       "      <td>0</td>\n",
       "      <td>alshabaab ended 2019 with a truckborne improvi...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>GPE end DATE truckborne improvise explosive de...</td>\n",
       "      <td>0.0277778</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212963</td>\n",
       "      <td>0</td>\n",
       "      <td>[GPE, end, DATE, truckborne, improvise, explos...</td>\n",
       "      <td>108</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://counteriedreport.com/al-shabaabs-impro...</td>\n",
       "      <td>Incident Report</td>\n",
       "      <td>0</td>\n",
       "      <td>alshabaab ended 2019 with a truckborne improvi...</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.5</td>\n",
       "      <td>GPE end DATE truckborne improvise explosive de...</td>\n",
       "      <td>0.0277778</td>\n",
       "      <td>0.037037</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212963</td>\n",
       "      <td>0</td>\n",
       "      <td>[GPE, end, DATE, truckborne, improvise, explos...</td>\n",
       "      <td>108</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url      class_label  \\\n",
       "0  https://www.nytimes.com/2020/08/17/world/afric...  Incident Report   \n",
       "1     https://www.bbc.com/news/world-europe-54500555  Incident Report   \n",
       "2  https://www.aljazeera.com/news/2020/10/12/nago...  Incident Report   \n",
       "3  https://counteriedreport.com/roadside-bomb-bla...  Incident Report   \n",
       "4  https://counteriedreport.com/al-shabaabs-impro...  Incident Report   \n",
       "\n",
       "   class_id                                               text ents_rep  \\\n",
       "0         0  advertisement supported by the extremist group...     1.52   \n",
       "1         0  belarusian riot police have used water cannon ...  1.41333   \n",
       "2         0  russian foreign minister calls on armenia and ...   2.2518   \n",
       "3         0  alshabaab ended 2019 with a truckborne improvi...     1.25   \n",
       "4         0  alshabaab ended 2019 with a truckborne improvi...     1.25   \n",
       "\n",
       "      vocab  ppo_rep                                       no_ents_text  \\\n",
       "0  0.570312  1.71875  advertisement support extremist group ORG esca...   \n",
       "1   0.57716  1.54902  NORP riot police water cannon stun grenade bre...   \n",
       "2  0.372881  2.62887  NORP foreign minister call GPE GPE adhere agre...   \n",
       "3      0.75      1.5  GPE end DATE truckborne improvise explosive de...   \n",
       "4      0.75      1.5  GPE end DATE truckborne improvise explosive de...   \n",
       "\n",
       "  verb_present  verb_past  ...         ad        prob  \\\n",
       "0     0.015625  0.0703125  ...   0.119792           0   \n",
       "1     0.037037  0.0432099  ...      0.125  0.00154321   \n",
       "2    0.0209847  0.0524617  ...  0.0992736  0.00161421   \n",
       "3    0.0277778   0.037037  ...   0.212963           0   \n",
       "4    0.0277778   0.037037  ...   0.212963           0   \n",
       "\n",
       "                                            lem_text   len org_count  \\\n",
       "0  [advertisement, support, extremist, group, ORG...   384  0.059896   \n",
       "1  [NORP, riot, police, water, cannon, stun, gren...   648  0.030864   \n",
       "2  [NORP, foreign, minister, call, GPE, GPE, adhe...  1239  0.066182   \n",
       "3  [GPE, end, DATE, truckborne, improvise, explos...   108  0.027778   \n",
       "4  [GPE, end, DATE, truckborne, improvise, explos...   108  0.027778   \n",
       "\n",
       "   place_count  time_count  person_count  num_count  ne_count  \n",
       "0     0.057292    0.039062      0.026042   0.015625  0.143229  \n",
       "1     0.026235    0.024691      0.064815   0.013889  0.121914  \n",
       "2     0.092010    0.033091      0.047619   0.012914  0.205811  \n",
       "3     0.027778    0.018519      0.000000   0.018519  0.055556  \n",
       "4     0.027778    0.018519      0.000000   0.018519  0.055556  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Individual model performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[['text','len', 'org_count', 'place_count', 'time_count', 'person_count', 'num_count', 'ents_rep', 'vocab', 'ppo_rep', 'verb_present', 'verb_past', 'verb', 'modal', 'ad', 'prob']]\n",
    "y = df[['class_label', 'class_id']]\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2, stratify=y, random_state=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rf = X_test[['len', 'org_count', 'place_count', 'time_count', 'person_count', 'num_count', 'ents_rep', 'vocab', 'ppo_rep', 'verb_present', 'verb_past', 'verb', 'modal', 'ad', 'prob']]\n",
    "y_rf = y_test['class_label']\n",
    "\n",
    "\n",
    "texts = X_test['text'].to_list()\n",
    "labels = y_test['class_id'].apply(lambda x:int(x))\n",
    "\n",
    "dataset = BertEncoder(\n",
    "    tokenizer=BertTokenizer.from_pretrained(\n",
    "        'bert-base-cased',\n",
    "        do_lower_case=False),\n",
    "    input_data=texts\n",
    ")\n",
    "\n",
    "tokenized_data = dataset.tokenize(max_len=510)\n",
    "\n",
    "input_ids, attention_masks = tokenized_data\n",
    "labels = torch.Tensor(labels.to_list()).long()\n",
    "\n",
    "dataloader = build_test_dataloaders(\n",
    "    input_ids=input_ids,\n",
    "    attention_masks=attention_masks,\n",
    "    labels=labels\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = pickle.load(open('./model/rf_model.sav', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "Analytical Report       0.88      0.93      0.90        15\n",
      "  Incident Report       0.94      0.83      0.88        18\n",
      "   Profile Report       0.78      0.90      0.84        20\n",
      " Situation Report       0.94      0.85      0.89        20\n",
      "\n",
      "         accuracy                           0.88        73\n",
      "        macro avg       0.88      0.88      0.88        73\n",
      "     weighted avg       0.88      0.88      0.88        73\n",
      "\n",
      "[[14  0  0  1]\n",
      " [ 0 15  3  0]\n",
      " [ 1  1 18  0]\n",
      " [ 1  0  2 17]]\n"
     ]
    }
   ],
   "source": [
    "# Please note the scores here are not the same as those in the traditional NLP notebook.\n",
    "# The reason is I accidentally ran tranditional NLP notebook random search cv again, \n",
    "# so the model there is not the same as the one save here. \n",
    "y_pred = rf.predict(X_rf)\n",
    "print(classification_report(y_rf, y_pred))\n",
    "print(confusion_matrix(y_rf, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_state_dict = torch.load('./model/trained_model.pt')\n",
    "bert = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-cased',\n",
    "    state_dict=bert_state_dict,\n",
    "    num_labels = 4,\n",
    "    output_attentions=False,\n",
    "    output_hidden_states=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.0034976  -1.4367361  -1.1977938  -2.1563373 ]\n",
      " [ 6.12242    -1.1885549  -1.7572205  -1.7771249 ]\n",
      " [ 1.9933681  -1.9661794   3.7339196  -3.634086  ]\n",
      " [-2.5564435  -1.8960001   5.8017936  -2.1922736 ]\n",
      " [-2.3510206  -1.8906516   5.90642    -2.382116  ]\n",
      " [ 6.0853243  -1.0437504  -1.8861271  -1.67723   ]\n",
      " [-1.4554386   4.9191628  -1.9625443  -1.5986322 ]\n",
      " [ 5.9895005  -1.2478404  -1.83326    -1.6556695 ]\n",
      " [-2.6087663  -1.9404153   5.72297    -1.9552666 ]\n",
      " [-2.405675   -1.869924    5.8454823  -2.2820027 ]\n",
      " [-1.0841643  -1.3103201   4.953755   -2.838082  ]\n",
      " [-2.2074788  -0.26162842 -2.205988    5.0521746 ]\n",
      " [-1.8595176  -1.3526336  -1.7825524   5.192944  ]\n",
      " [-1.9011126  -1.2507565  -1.8456715   5.078395  ]\n",
      " [ 6.081219   -1.301969   -1.7657568  -1.609917  ]\n",
      " [-1.5199683   4.8878284  -1.9637839  -1.4974451 ]\n",
      " [-1.8598015  -0.94654393 -2.0823646   5.2278214 ]\n",
      " [-2.4640503  -1.8799112   5.871163   -2.378856  ]\n",
      " [-1.945038   -0.8934976  -2.1046457   5.2174597 ]\n",
      " [ 6.098221   -1.3404071  -1.6537436  -1.8217322 ]\n",
      " [-1.3639364   4.633088   -2.1293268  -1.0767865 ]\n",
      " [-2.015501   -0.8348365  -2.1373663   5.1999817 ]\n",
      " [-2.2941487  -1.7570381   5.597165   -2.1221788 ]\n",
      " [ 1.2719162  -2.0093784   4.450482   -3.6800277 ]\n",
      " [ 6.14241    -1.1969848  -1.6907502  -1.8266743 ]\n",
      " [-1.3327167   4.8934417  -2.022952   -1.5703486 ]\n",
      " [ 4.2832165   0.66083515 -2.3661556  -1.401353  ]\n",
      " [-1.3795698   3.5506322  -2.2274046   0.29103652]\n",
      " [-2.3777413  -1.899983    5.865141   -2.318752  ]\n",
      " [-2.419071   -0.5757867   4.5956903  -2.312246  ]\n",
      " [ 5.9027514  -1.1074891  -1.8723391  -1.6024356 ]\n",
      " [ 5.12124    -1.6778115   0.45311698 -2.8044426 ]\n",
      " [-1.8213867  -0.8562191  -2.1759212   5.2388034 ]\n",
      " [-2.638738   -1.841842    5.7419095  -1.9449693 ]\n",
      " [-1.319802    3.105771   -2.3141088   0.9900717 ]\n",
      " [ 5.978823   -0.95609623 -1.9217738  -1.7698015 ]\n",
      " [-1.3869066   4.9532275  -1.9629545  -1.6721785 ]\n",
      " [-1.8986003  -0.8522004  -2.0751143   5.2159424 ]\n",
      " [-2.1435525  -0.06669997 -2.1539617   4.711008  ]\n",
      " [-1.527823    4.927121   -1.8910776  -1.6526917 ]\n",
      " [ 4.522121   -1.8828847   1.403091   -3.1386554 ]\n",
      " [ 6.1196303  -1.1183923  -1.8396338  -1.7415295 ]\n",
      " [-1.9097046  -1.9615196   5.877832   -2.6848412 ]\n",
      " [-1.7722945   1.0667117  -2.3475752   3.4474218 ]\n",
      " [-2.2251325  -0.5110595  -2.0881824   5.0518446 ]\n",
      " [-1.294141    0.34355232 -2.2887976   3.8893783 ]\n",
      " [-0.3738404   3.927462   -2.5375628  -0.6110992 ]\n",
      " [-1.5437312   4.9117737  -1.8728374  -1.66177   ]\n",
      " [ 4.812945    0.01168947 -2.3127074  -1.3421897 ]\n",
      " [-1.4698421   4.931679   -1.9429876  -1.6251854 ]\n",
      " [-2.416084   -2.0010624   5.9337463  -2.361819  ]\n",
      " [ 6.1036134  -1.1017886  -1.7948451  -1.7977103 ]\n",
      " [-1.4776216   4.9311476  -1.911863   -1.650539  ]\n",
      " [-1.4740405   4.937499   -1.9244276  -1.6265315 ]\n",
      " [-1.231951    4.7438164  -2.1828015  -1.3003272 ]\n",
      " [ 4.9942966   0.24195287 -2.4722083  -1.5633265 ]\n",
      " [-1.5571349   4.92458    -1.8640494  -1.6855897 ]\n",
      " [-1.4419998   4.9199934  -1.974085   -1.5546422 ]\n",
      " [-2.4648812  -1.7832253   5.772899   -2.37138   ]\n",
      " [-2.2682977  -0.9581092  -1.8652072   5.238017  ]\n",
      " [-1.4200506   4.856648   -2.0477743  -1.4112847 ]\n",
      " [ 6.0851884  -0.9996674  -1.7808243  -1.926578  ]\n",
      " [-1.2106843   1.3754703  -2.369113    2.7959425 ]\n",
      " [-1.41145     4.7623467  -2.077094   -1.2350999 ]\n",
      " [ 5.4644895  -1.8019333   0.16433258 -2.7607987 ]\n",
      " [ 6.1166344  -1.291268   -1.7120649  -1.7255982 ]\n",
      " [ 5.9979577  -1.1329454  -1.946116   -1.6403183 ]\n",
      " [-1.6069767   4.932618   -1.8268944  -1.6785203 ]\n",
      " [ 0.6691426   1.0628041  -2.6772342   1.8759536 ]\n",
      " [-2.3366764  -1.8840835   5.875195   -2.4308054 ]\n",
      " [-1.5993209   4.3840237  -1.8534195  -0.8090729 ]\n",
      " [-1.9792119  -1.1378808  -1.8517212   5.170456  ]\n",
      " [ 6.1405935  -1.2201923  -1.7424204  -1.7933658 ]]\n"
     ]
    }
   ],
   "source": [
    "y_b_pred, _ = bert_predict(bert, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "  Incident Report       0.81      0.94      0.87        18\n",
      " Situation Report       0.95      0.95      0.95        20\n",
      "   Profile report       1.00      0.80      0.89        20\n",
      "Analytical report       0.88      0.93      0.90        15\n",
      "\n",
      "         accuracy                           0.90        73\n",
      "        macro avg       0.91      0.91      0.90        73\n",
      "     weighted avg       0.91      0.90      0.90        73\n",
      "\n",
      "[[17  0  0  1]\n",
      " [ 0 19  0  1]\n",
      " [ 4  0 16  0]\n",
      " [ 0  1  0 14]]\n"
     ]
    }
   ],
   "source": [
    "cls_names = ['Incident Report', 'Situation Report', 'Profile report', 'Analytical report']\n",
    "print(classification_report(labels, y_b_pred, target_names=cls_names))\n",
    "print(confusion_matrix(labels, y_b_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Ensemble\n",
    "Considering that random forest took little time to train, the result is really good. However, the purpose of this notebook is to look at if ensemble both models will produce better result. </n>\n",
    "\n",
    "First, let's look at if both models predict the same labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_b_pred = [int(x) for x in y_b_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest misclassified groud truth: 96        Profile Report\n",
      "81      Situation Report\n",
      "86       Incident Report\n",
      "48     Analytical Report\n",
      "148       Profile Report\n",
      "83       Incident Report\n",
      "323     Situation Report\n",
      "281     Situation Report\n",
      "259      Incident Report\n",
      "Name: class_label, dtype: object\n",
      "Random forest misclassified predicted: ['Analytical Report' 'Analytical Report' 'Profile Report'\n",
      " 'Situation Report' 'Incident Report' 'Profile Report' 'Profile Report'\n",
      " 'Profile Report' 'Profile Report']\n",
      "\n",
      "BERT model misclassified ground truth 140       Profile Report\n",
      "159       Profile Report\n",
      "48     Analytical Report\n",
      "148       Profile Report\n",
      "281     Situation Report\n",
      "149       Profile Report\n",
      "259      Incident Report\n",
      "Name: class_label, dtype: object\n",
      "BERT model misclassified predicted [0 0 1 0 3 0 3]\n"
     ]
    }
   ],
   "source": [
    "print('Random forest misclassified groud truth:', y_rf[y_rf!=y_pred])\n",
    "print('Random forest misclassified predicted:', y_pred[y_rf!=y_pred])\n",
    "print()\n",
    "y_nn = labels.numpy()\n",
    "print('BERT model misclassified ground truth', y_test['class_label'][y_nn!=y_b_pred])\n",
    "print('BERT model misclassified predicted', np.array(y_b_pred)[y_nn!=y_b_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some overlap (48, 148, 281, 259) but more misclassified cases of different samples. Even the overlapped misclassification, the predicitons are different between these two models. There is now a good intuition for ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = NLPEnsemble(\n",
    "    traditional_nlp=rf,\n",
    "    nn_nlp=bert\n",
    ")\n",
    "\n",
    "pred = ensemble.predict(X_rf, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
